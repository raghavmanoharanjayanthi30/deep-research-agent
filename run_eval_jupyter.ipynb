{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f139ccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # loads from .env file\n",
    "\n",
    "os.environ['GEMINI_API_KEY'] = os.getenv(\"GEMINI_API_KEY\")\n",
    "os.environ['TAVILY_API_KEY'] = os.getenv(\"TAVILY_API_KEY\")\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6756d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import argparse\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "from tavily import TavilyClient\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Import your agent building blocks\n",
    "from research_assistant_refactor_v16_disamb_flow_fix import (\n",
    "    init_state,\n",
    "    plan_node,\n",
    "    search_node,\n",
    "    fetch_node,\n",
    "    extract_node,\n",
    "    integrate_node,\n",
    "    PatchApplier,\n",
    ")\n",
    "\n",
    "def pick_open_lead(state: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Pick the highest-priority open lead (generic, no topic logic).\"\"\"\n",
    "    leads = state.get(\"leads\", []) or []\n",
    "    open_leads = [l for l in leads if l.get(\"status\", \"open\") == \"open\"]\n",
    "    if not open_leads:\n",
    "        return None\n",
    "    # Sort: highest priority first; tiebreaker: shallower depth first, then newest\n",
    "    open_leads.sort(\n",
    "        key=lambda x: (\n",
    "            float(x.get(\"priority\", 0.0)),\n",
    "            -float(x.get(\"depth\", 0.0)),\n",
    "            x.get(\"created_at\", \"\")\n",
    "        ),\n",
    "        reverse=True\n",
    "    )\n",
    "    return open_leads[0]\n",
    "\n",
    "# -------------------------\n",
    "# Tavily search function\n",
    "# -------------------------\n",
    "def tavily_search_fn(query: str, max_results: int = 3):\n",
    "    api_key = os.environ.get(\"TAVILY_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\"Missing TAVILY_API_KEY\")\n",
    "\n",
    "    client = TavilyClient(api_key=api_key)\n",
    "    resp = client.search(\n",
    "        query=query,\n",
    "        max_results=max_results,\n",
    "        search_depth=\"advanced\",\n",
    "        include_answer=False,\n",
    "        include_raw_content=False,\n",
    "    )\n",
    "\n",
    "    out = []\n",
    "    for r in resp.get(\"results\", []):\n",
    "        url = r.get(\"url\")\n",
    "        if not url:\n",
    "            continue\n",
    "        out.append(\n",
    "            {\n",
    "                \"title\": r.get(\"title\", \"\"),\n",
    "                \"url\": url,\n",
    "                \"snippet\": (r.get(\"content\") or \"\")[:1200],\n",
    "                \"published_at\": r.get(\"published_date\") or None,\n",
    "                \"provider\": \"tavily\",\n",
    "                \"credibility\": float(r.get(\"score\", 0.5)),\n",
    "            }\n",
    "        )\n",
    "    return out\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Non-interactive disambiguation (generic)\n",
    "# -------------------------\n",
    "def disambiguate_auto(\n",
    "    llm_reason,\n",
    "    search_fn,\n",
    "    state: Dict[str, Any],\n",
    "    hint: Optional[str] = None,\n",
    "    max_rounds: int = 2,\n",
    "    k_results: int = 6,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Generic offline identity resolution:\n",
    "    - search for disambiguation candidates\n",
    "    - ask LLM to pick best candidate given (target + hint)\n",
    "    - store canonical_name + chosen_candidate_id + anchors (seed_urls)\n",
    "    \"\"\"\n",
    "    target = (state.get(\"target\") or {}).get(\"raw_input\") or \"\"\n",
    "\n",
    "    # We only need this if the agent relies on canonical_name for good queries\n",
    "    # If you already have canonical_name, keep it.\n",
    "    if (state.get(\"target\") or {}).get(\"canonical_name\"):\n",
    "        return state\n",
    "\n",
    "    for _round in range(max_rounds):\n",
    "        q = f\"{target} disambiguation\"\n",
    "        if hint:\n",
    "            q = f\"{target} {hint} disambiguation\"\n",
    "\n",
    "        results = search_fn(q, max_results=k_results)\n",
    "\n",
    "        # Build lightweight candidate list (URLs/titles/snips) for LLM\n",
    "        # Group by URL domain heuristics and title uniqueness\n",
    "        candidates = []\n",
    "        for r in results:\n",
    "            candidates.append(\n",
    "                {\n",
    "                    \"url\": r.get(\"url\"),\n",
    "                    \"title\": r.get(\"title\"),\n",
    "                    \"snippet\": (r.get(\"snippet\") or \"\")[:350],\n",
    "                    \"credibility\": float(r.get(\"credibility\", 0.5)),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "SYSTEM:\n",
    "You are an identity disambiguation module.\n",
    "Given a target name and optional hint, choose the best matching identity candidate from search results.\n",
    "Return STRICT JSON only:\n",
    "{{\n",
    "  \"canonical_name\": string,\n",
    "  \"confidence\": number,\n",
    "  \"seed_urls\": [string, ...],\n",
    "  \"rationale\": string\n",
    "}}\n",
    "\n",
    "RULES:\n",
    "- Prefer candidates that clearly match the hint if provided.\n",
    "- Prefer high-credibility sources.\n",
    "- Prefer Wikipedia/official/primary profiles when available.\n",
    "- If unsure, choose the best-supported option and lower confidence.\n",
    "\n",
    "USER:\n",
    "target: {target}\n",
    "hint: {hint or \"\"}\n",
    "\n",
    "candidates:\n",
    "{json.dumps(candidates, ensure_ascii=False)}\n",
    "\"\"\".strip()\n",
    "\n",
    "        resp = llm_reason.invoke(prompt) if hasattr(llm_reason, \"invoke\") else llm_reason(prompt)\n",
    "        text = getattr(resp, \"content\", resp)\n",
    "\n",
    "        try:\n",
    "            out = json.loads(text)\n",
    "        except Exception:\n",
    "            # very small repair: extract first {...}\n",
    "            start = text.find(\"{\")\n",
    "            end = text.rfind(\"}\")\n",
    "            if start != -1 and end != -1 and end > start:\n",
    "                out = json.loads(text[start : end + 1])\n",
    "            else:\n",
    "                out = {}\n",
    "\n",
    "        canonical = (out or {}).get(\"canonical_name\")\n",
    "        if canonical:\n",
    "            state[\"target\"][\"canonical_name\"] = canonical\n",
    "            # pseudo-id so downstream prints don't break\n",
    "            state[\"target\"][\"chosen_candidate_id\"] = state[\"target\"].get(\"chosen_candidate_id\") or \"auto\"\n",
    "            seed_urls = (out or {}).get(\"seed_urls\") or []\n",
    "            if seed_urls:\n",
    "                state[\"target\"][\"seed_urls\"] = list(dict.fromkeys(seed_urls))\n",
    "            state[\"target\"].setdefault(\"hints\", {})\n",
    "            if hint:\n",
    "                state[\"target\"][\"hints\"][\"disambiguation_hint\"] = hint\n",
    "            return state\n",
    "\n",
    "        # If LLM couldn't pick, try again with no hint or stop\n",
    "        hint = None\n",
    "\n",
    "    # fallback: keep raw_input as canonical name\n",
    "    state[\"target\"][\"canonical_name\"] = state[\"target\"][\"raw_input\"]\n",
    "    state[\"target\"][\"chosen_candidate_id\"] = state[\"target\"].get(\"chosen_candidate_id\") or \"auto_fallback\"\n",
    "    return state\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# LangGraph loop (same structure as graph4)\n",
    "# -------------------------\n",
    "# def node_plan(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "#     topics = state.get(\"topics\", {}) or {}\n",
    "#     incomplete = []\n",
    "#     for name, t in topics.items():\n",
    "#         if (t or {}).get(\"status\") != \"complete\":\n",
    "#             incomplete.append((name, t))\n",
    "#     incomplete.sort(key=lambda nt: int((nt[1] or {}).get(\"priority\", 999)))\n",
    "#     topics_to_work = [name for name, _ in incomplete]\n",
    "\n",
    "#     # store for integrate prompt prioritization\n",
    "#     state[\"_topics_to_work\"] = topics_to_work\n",
    "\n",
    "#     if not topics_to_work and not (state.get(\"leads\") or []):\n",
    "#         state[\"_last_plan\"] = {\"queries\": []}\n",
    "#         return state\n",
    "\n",
    "#     plan = plan_node(\n",
    "#         state[\"llm_reason\"],\n",
    "#         state,\n",
    "#         topics_to_work,\n",
    "#         lead_to_work=None,\n",
    "#         k=int(state[\"control\"].get(\"k_queries\", 6)),\n",
    "#     )\n",
    "#     state[\"_last_plan\"] = plan\n",
    "#     return state\n",
    "\n",
    "def node_plan(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    topics = state.get(\"topics\", {}) or {}\n",
    "\n",
    "    incomplete = []\n",
    "    for name, t in topics.items():\n",
    "        if t.get(\"status\") != \"complete\":\n",
    "            incomplete.append((name, t))\n",
    "\n",
    "    # sort by declared topic priority if available\n",
    "    incomplete.sort(key=lambda nt: int((nt[1] or {}).get(\"priority\", 999)))\n",
    "    topics_to_work = [name for name, _ in incomplete]\n",
    "\n",
    "    # Risk-first scheduling (simple risk pass)\n",
    "    if \"risk_inconsistencies\" in topics_to_work:\n",
    "        topics_to_work.remove(\"risk_inconsistencies\")\n",
    "        topics_to_work.insert(0, \"risk_inconsistencies\")\n",
    "\n",
    "    # expose to LLM for better planning/integration targeting\n",
    "    state[\"_topics_to_work\"] = topics_to_work\n",
    "\n",
    "    lead_to_work = pick_open_lead(state)\n",
    "\n",
    "    if not topics_to_work and not lead_to_work:\n",
    "        state[\"_last_plan\"] = {\"queries\": []}\n",
    "        return state\n",
    "\n",
    "    print(\"topics_to_work:\", topics_to_work)\n",
    "    if lead_to_work:\n",
    "        print(\"lead_to_work:\", lead_to_work.get(\"title\"), \"| p=\", lead_to_work.get(\"priority\"), \"depth=\", lead_to_work.get(\"depth\"))\n",
    "\n",
    "    plan = plan_node(\n",
    "        state[\"llm_reason\"],\n",
    "        state,\n",
    "        topics_to_work,\n",
    "        lead_to_work,\n",
    "        k=int(state[\"control\"].get(\"k_queries\", 6)),\n",
    "    )\n",
    "    state[\"_last_plan\"] = plan\n",
    "\n",
    "    try:\n",
    "        qs = plan.get(\"queries\", [])\n",
    "        print(\"planned queries:\", len(qs))\n",
    "        for q in qs[:6]:\n",
    "            print(\"  -\", q.get(\"q\") or q.get(\"query\"), \"|\", q.get(\"intent\"), \"|\", q.get(\"desired_field\"))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "def node_search(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    plan = state.get(\"_last_plan\") or {\"queries\": []}\n",
    "    new_eids = search_node(state[\"search_fn\"], state, plan)\n",
    "    state[\"_new_eids\"] = new_eids\n",
    "    return state\n",
    "\n",
    "\n",
    "def node_fetch(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    fetch_node(state)\n",
    "    return state\n",
    "\n",
    "\n",
    "def node_extract(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    eids = state.get(\"_new_eids\", [])\n",
    "    new_claim_ids, _ = extract_node(state[\"llm_extract\"], state, eids)\n",
    "    state[\"_new_claim_ids\"] = new_claim_ids\n",
    "    return state\n",
    "\n",
    "\n",
    "def node_integrate(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    patches = integrate_node(state[\"llm_reason\"], state, state.get(\"_new_claim_ids\", []))\n",
    "    state[\"_patches\"] = patches\n",
    "    return state\n",
    "\n",
    "\n",
    "def node_apply(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    state[\"applier\"].apply(state, state.get(\"_patches\", {}))\n",
    "    state[\"control\"][\"_iters_done\"] = int(state[\"control\"].get(\"_iters_done\", 0)) + 1\n",
    "    return state\n",
    "\n",
    "\n",
    "def should_continue(state: Dict[str, Any]) -> str:\n",
    "    max_it = int(state[\"control\"].get(\"max_iterations\", 3))\n",
    "    it = int(state[\"control\"].get(\"_iters_done\", 0))\n",
    "    if it >= max_it:\n",
    "        return \"end\"\n",
    "\n",
    "    topics = state.get(\"topics\", {}) or {}\n",
    "    if topics and all((t.get(\"status\") == \"complete\") for t in topics.values()):\n",
    "        return \"end\"\n",
    "\n",
    "    return \"loop\"\n",
    "\n",
    "\n",
    "def build_graph():\n",
    "    g = StateGraph(dict)\n",
    "    g.add_node(\"plan\", node_plan)\n",
    "    g.add_node(\"search\", node_search)\n",
    "    g.add_node(\"fetch\", node_fetch)\n",
    "    g.add_node(\"extract\", node_extract)\n",
    "    g.add_node(\"integrate\", node_integrate)\n",
    "    g.add_node(\"apply\", node_apply)\n",
    "\n",
    "    g.set_entry_point(\"plan\")\n",
    "    g.add_edge(\"plan\", \"search\")\n",
    "    g.add_edge(\"search\", \"fetch\")\n",
    "    g.add_edge(\"fetch\", \"extract\")\n",
    "    g.add_edge(\"extract\", \"integrate\")\n",
    "    g.add_edge(\"integrate\", \"apply\")\n",
    "    g.add_conditional_edges(\"apply\", should_continue, {\"loop\": \"plan\", \"end\": END})\n",
    "    return g.compile()\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Report flattening + baseline scoring\n",
    "# -------------------------\n",
    "def flatten_text(obj: Any) -> str:\n",
    "    if obj is None:\n",
    "        return \"\"\n",
    "    if isinstance(obj, str):\n",
    "        return obj\n",
    "    if isinstance(obj, (int, float, bool)):\n",
    "        return str(obj)\n",
    "    if isinstance(obj, list):\n",
    "        return \" \".join(flatten_text(x) for x in obj)\n",
    "    if isinstance(obj, dict):\n",
    "        return \" \".join(flatten_text(v) for v in obj.values())\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def keyword_fact_hit(report_text: str, must: List[str], should: List[str]) -> Tuple[bool, float]:\n",
    "    text = report_text.lower()\n",
    "    must_ok = all(m.lower() in text for m in (must or []))\n",
    "    if not must_ok:\n",
    "        return False, 0.0\n",
    "    if not should:\n",
    "        return True, 1.0\n",
    "    should_hits = sum(1 for s in should if s.lower() in text)\n",
    "    return True, should_hits / max(1, len(should))\n",
    "\n",
    "\n",
    "def compute_structural_metrics(state: Dict[str, Any], topic_specs_by_name: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    topics = state.get(\"topics\", {}) or {}\n",
    "    evidence = state.get(\"evidence\", []) or []\n",
    "    ev_by_id = {e.get(\"id\"): e for e in evidence if isinstance(e, dict) and e.get(\"id\")}\n",
    "    citations = state.get(\"_field_citations\", {}) or {}\n",
    "\n",
    "    out = {\n",
    "        \"topics\": {},\n",
    "        \"overall\": {\n",
    "            \"topics_complete\": 0,\n",
    "            \"topics_total\": 0,\n",
    "            \"field_coverage_avg\": 0.0,\n",
    "            \"distinct_source_urls\": len({e.get(\"url\") for e in evidence if e.get(\"url\")}),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    coverages = []\n",
    "    complete = 0\n",
    "    total = 0\n",
    "\n",
    "    for tname, t in topics.items():\n",
    "        total += 1\n",
    "        spec = topic_specs_by_name.get(tname, {})\n",
    "        req = spec.get(\"required_fields\") or (t.get(\"required_fields\") or [])\n",
    "        pf = t.get(\"populated_fields\") or {}\n",
    "        missing = t.get(\"missing_fields\") or []\n",
    "\n",
    "        # field coverage\n",
    "        have_count = 0\n",
    "        for f in req:\n",
    "            val = pf.get(f)\n",
    "            if isinstance(val, list) and len(val) > 0:\n",
    "                have_count += 1\n",
    "        cov = have_count / max(1, len(req))\n",
    "        coverages.append(cov)\n",
    "\n",
    "        # source quality vs spec thresholds (based on field citations)\n",
    "        t_cit = (citations.get(tname) or {})\n",
    "        all_eids = []\n",
    "        for f in req:\n",
    "            all_eids.extend(t_cit.get(f) or [])\n",
    "        all_eids = list(dict.fromkeys([x for x in all_eids if isinstance(x, str)]))\n",
    "\n",
    "        min_cred = float(spec.get(\"min_credibility\", 0.0) or 0.0)\n",
    "        good = []\n",
    "        for eid in all_eids:\n",
    "            ev = ev_by_id.get(eid) or {}\n",
    "            try:\n",
    "                if float(ev.get(\"credibility\", 0.0)) >= min_cred:\n",
    "                    good.append(eid)\n",
    "            except Exception:\n",
    "                pass\n",
    "        good = list(dict.fromkeys(good))\n",
    "\n",
    "        out[\"topics\"][tname] = {\n",
    "            \"status\": t.get(\"status\"),\n",
    "            \"missing_fields\": missing,\n",
    "            \"required_fields\": req,\n",
    "            \"field_coverage\": cov,\n",
    "            \"evidence_ids_total\": len(all_eids),\n",
    "            \"good_evidence_ids\": len(good),\n",
    "            \"min_credibility\": min_cred,\n",
    "        }\n",
    "\n",
    "        if t.get(\"status\") == \"complete\":\n",
    "            complete += 1\n",
    "\n",
    "    out[\"overall\"][\"topics_complete\"] = complete\n",
    "    out[\"overall\"][\"topics_total\"] = total\n",
    "    out[\"overall\"][\"field_coverage_avg\"] = sum(coverages) / max(1, len(coverages))\n",
    "    return out\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# LLM Judge\n",
    "# -------------------------\n",
    "def llm_judge_case(llm_judge, report_text: str, expected_facts: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    prompt = f\"\"\"\n",
    "SYSTEM:\n",
    "You are an evaluator. You will judge whether the agent report supports each expected fact.\n",
    "Return STRICT JSON ONLY:\n",
    "{{\n",
    "  \"facts\": [\n",
    "    {{\n",
    "      \"id\": string,\n",
    "      \"covered\": boolean,\n",
    "      \"confidence\": number,\n",
    "      \"evidence_in_report\": string\n",
    "    }}\n",
    "  ],\n",
    "  \"overall_score\": number\n",
    "}}\n",
    "\n",
    "RULES:\n",
    "- \"covered\" means the report contains enough info to reasonably support the fact.\n",
    "- Prefer explicit mentions. If only implied, lower confidence.\n",
    "- evidence_in_report should be a short quote-like excerpt (<= 25 words) copied from the report.\n",
    "\n",
    "REPORT:\n",
    "{report_text}\n",
    "\n",
    "EXPECTED FACTS:\n",
    "{json.dumps(expected_facts, ensure_ascii=False)}\n",
    "\"\"\".strip()\n",
    "\n",
    "    resp = llm_judge.invoke(prompt) if hasattr(llm_judge, \"invoke\") else llm_judge(prompt)\n",
    "    text = getattr(resp, \"content\", resp)\n",
    "\n",
    "    # parse\n",
    "    try:\n",
    "        out = json.loads(text)\n",
    "    except Exception:\n",
    "        start = text.find(\"{\")\n",
    "        end = text.rfind(\"}\")\n",
    "        out = json.loads(text[start : end + 1]) if start != -1 and end != -1 and end > start else {}\n",
    "\n",
    "    # sanity\n",
    "    facts = out.get(\"facts\") if isinstance(out, dict) else None\n",
    "    if not isinstance(facts, list):\n",
    "        out = {\"facts\": [], \"overall_score\": 0.0}\n",
    "    return out\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Format report (simple)\n",
    "# -------------------------\n",
    "def format_report_for_eval(state: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Keep this simple + stable for eval. Uses populated_fields only.\n",
    "    If you already have a better format_report in graph4, you can import it instead.\n",
    "    \"\"\"\n",
    "    topics = state.get(\"topics\", {}) or {}\n",
    "    tgt = state.get(\"target\", {}) or {}\n",
    "    lines = []\n",
    "    lines.append(f\"TARGET: {tgt.get('canonical_name') or tgt.get('raw_input')}\")\n",
    "    for tname, t in topics.items():\n",
    "        lines.append(f\"\\nTOPIC: {tname}\")\n",
    "        lines.append(f\"status: {t.get('status')}\")\n",
    "        pf = t.get(\"populated_fields\") or {}\n",
    "        for k, v in pf.items():\n",
    "            lines.append(f\"- {k}: {v}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Main eval runner\n",
    "# -------------------------\n",
    "def run_case(\n",
    "    case: Dict[str, Any],\n",
    "    llm_reason,\n",
    "    llm_extract,\n",
    "    llm_judge,\n",
    "    allowed_topics: Optional[set] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    state = init_state(case[\"target\"])\n",
    "\n",
    "    # Limit topics for eval to what you care about\n",
    "    if allowed_topics:\n",
    "        state[\"topics\"] = {k: v for k, v in state.get(\"topics\", {}).items() if k in allowed_topics}\n",
    "\n",
    "    # Attach deps\n",
    "    state[\"llm_reason\"] = llm_reason\n",
    "    state[\"llm_extract\"] = llm_extract\n",
    "    state[\"search_fn\"] = tavily_search_fn\n",
    "    state[\"applier\"] = PatchApplier()\n",
    "\n",
    "    # Control knobs\n",
    "    state[\"control\"][\"max_iterations\"] = int(case.get(\"max_iterations\", 2))\n",
    "    state[\"control\"][\"k_queries\"] = int(case.get(\"k_queries\", 6))\n",
    "\n",
    "    # Offline disambiguation\n",
    "    hint = case.get(\"disambiguation_hint\")\n",
    "    state = disambiguate_auto(llm_reason, tavily_search_fn, state, hint=hint, max_rounds=2)\n",
    "\n",
    "    # Run graph\n",
    "    app = build_graph()\n",
    "    t0 = time.time()\n",
    "    final_state = app.invoke(state)\n",
    "    runtime_s = time.time() - t0\n",
    "\n",
    "    report_text = format_report_for_eval(final_state)\n",
    "\n",
    "    # Structural metrics\n",
    "    # If your TOPIC_SPECS_BY_NAME is defined in the refactor file, import it and use it here.\n",
    "    # For now, derive a simple spec from state topics as fallback.\n",
    "    topic_specs_by_name = {}\n",
    "    for tname, t in (final_state.get(\"topics\") or {}).items():\n",
    "        topic_specs_by_name[tname] = {\n",
    "            \"required_fields\": (t.get(\"required_fields\") or []),\n",
    "            \"min_credibility\": 0.0\n",
    "        }\n",
    "\n",
    "    structural = compute_structural_metrics(final_state, topic_specs_by_name)\n",
    "\n",
    "    # Baseline expected-field checks (keyword-ish)\n",
    "    expected = case.get(\"expected\") or {}\n",
    "    expected_hits = {}\n",
    "    for topic, fields in expected.items():\n",
    "        pf = (((final_state.get(\"topics\") or {}).get(topic) or {}).get(\"populated_fields\") or {})\n",
    "        blob = flatten_text(pf).lower()\n",
    "        field_hits = {}\n",
    "        for field, toks in (fields or {}).items():\n",
    "            if not toks:\n",
    "                field_hits[field] = None\n",
    "            else:\n",
    "                field_hits[field] = any(str(tok).lower() in blob for tok in toks)\n",
    "        expected_hits[topic] = field_hits\n",
    "\n",
    "    # Fact checks: baseline + LLM judge\n",
    "    expected_facts = case.get(\"expected_facts\") or []\n",
    "    baseline_fact = []\n",
    "    for f in expected_facts:\n",
    "        ok, score = keyword_fact_hit(report_text, f.get(\"must_mention\") or [], f.get(\"should_mention\") or [])\n",
    "        baseline_fact.append({\"id\": f.get(\"id\"), \"covered\": ok, \"partial_score\": score})\n",
    "\n",
    "    judge = llm_judge_case(llm_judge, report_text, expected_facts) if expected_facts else {\"facts\": [], \"overall_score\": 0.0}\n",
    "\n",
    "    return {\n",
    "        \"case_id\": case.get(\"id\"),\n",
    "        \"target\": case.get(\"target\"),\n",
    "        \"canonical_name\": (final_state.get(\"target\") or {}).get(\"canonical_name\"),\n",
    "        \"runtime_s\": runtime_s,\n",
    "        \"structural\": structural,\n",
    "        \"expected_field_hits\": expected_hits,\n",
    "        \"baseline_fact_hits\": baseline_fact,\n",
    "        \"llm_judge\": judge,\n",
    "        \"report_text\": report_text,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e72d516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = \" \".join(str(current_datetime).split(' ')).replace('-', '_').replace(' ','__').replace(':', '_')\n",
    "evalset=f\"evalset.json\"\n",
    "out=f\"eval_results_{now}.json\"\n",
    "model_reason=\"gpt-4o\"\n",
    "model_extract=\"gpt-4o-mini\"\n",
    "model_judge=\"gpt-4o\"\n",
    "\n",
    "llm_reason = ChatOpenAI(model=model_reason, temperature=0)\n",
    "llm_extract = ChatOpenAI(model=model_extract, temperature=0)\n",
    "llm_judge = ChatOpenAI(model=model_judge, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55e6256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(evalset, \"r\") as f:\n",
    "    evalset_data = json.load(f)\n",
    "\n",
    "cases = evalset_data.get(\"cases\", [])\n",
    "allowed_topics = {\"identity\", \"professional_timeline\", \"risk_inconsistencies\", \"legal_regulatory\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40341127",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running case_theranos_holmes :: Elizabeth Holmes ===\n",
      "TOPICS_TO_WORK: ['identity', 'professional_timeline', 'legal_regulatory', 'risk_inconsistencies']\n",
      "MISSING_FIELDS: {'identity': ['name_variants', 'date_of_birth', 'nationalities', 'general_location', 'associated_orgs'], 'professional_timeline': ['roles', 'employers', 'board_positions', 'education', 'role_dates'], 'legal_regulatory': ['criminal_records', 'civil_cases', 'regulatory_actions', 'sanctions_list_mentions', 'court_involvement'], 'risk_inconsistencies': ['identity_conflicts', 'employment_conflicts', 'ownership_conflicts', 'timeline_gaps', 'misrepresentation_indicators']}\n",
      "SAMPLE_COMPACT_CLAIMS: [\n",
      "  {\n",
      "    \"id\": \"clm_1\",\n",
      "    \"type\": null,\n",
      "    \"text\": null,\n",
      "    \"confidence\": 1.0,\n",
      "    \"evidence_ids\": [\n",
      "      \"ev_905ff16389\"\n",
      "    ],\n",
      "    \"entity_refs\": [],\n",
      "    \"when\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"clm_2\",\n",
      "    \"type\": null,\n",
      "    \"text\": null,\n",
      "    \"confidence\": 1.0,\n",
      "    \"evidence_ids\": [\n",
      "      \"ev_905ff16389\"\n",
      "    ],\n",
      "    \"entity_refs\": [],\n",
      "    \"when\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"clm_3\",\n",
      "    \"type\": null,\n",
      "    \"text\": null,\n",
      "    \"confidence\": 1.0,\n",
      "    \"evidence_ids\": [\n",
      "      \"ev_dcf2ad8282\"\n",
      "    ],\n",
      "    \"entity_refs\": [],\n",
      "    \"when\": null\n",
      "  }\n",
      "]\n",
      "SAMPLE_EVID_SNIPS: [\n",
      "  [\n",
      "    \"ev_905ff16389\",\n",
      "    {\n",
      "      \"title\": \"Theranos - Wikipedia\",\n",
      "      \"url\": \"https://en.wikipedia.org/wiki/Theranos\",\n",
      "      \"snippet\": \"| Key people |  Elizabeth Holmes (CEO)  Sunny Balwani (COO)  Ian Gibbons \\\"Ian Gibbons (biochemist)\\\") (CSO) |\\n| Creditors, investors, and partners |  Walgreens  Safeway  Cleveland Clinic  Novartis  GSK  Fortress Investment Group  Pfizer  Walton family  Rupert Murdoch  Betsy Devos |\\n| Investigation |  Wall Street Journal Theranos investigation  John \"\n",
      "    }\n",
      "  ],\n",
      "  [\n",
      "    \"ev_dcf2ad8282\",\n",
      "    {\n",
      "      \"title\": \"Fake It Till You Fail: Elizabeth Holmes and the Theranos Story\",\n",
      "      \"url\": \"https://ideas.darden.virginia.edu/theranos-darden-case\",\n",
      "      \"snippet\": \"Alexander is a governing board member of the Small Business Investor Alliance (SBIA) and serves on its executive committee. He founded the Louisiana chapter of the Association for Corporate Growth (ACG), served as its first chapter president, and remains a board member. He was the ACG Global Chairman of Finance, an executive committee member, a glo\"\n",
      "    }\n",
      "  ]\n",
      "]\n",
      "TOPICS_TO_WORK: ['identity', 'professional_timeline', 'legal_regulatory', 'risk_inconsistencies']\n",
      "MISSING_FIELDS: {'identity': ['name_variants', 'nationalities'], 'professional_timeline': ['roles', 'employers', 'board_positions', 'role_dates'], 'legal_regulatory': ['civil_cases', 'regulatory_actions', 'sanctions_list_mentions', 'court_involvement'], 'risk_inconsistencies': ['identity_conflicts', 'employment_conflicts', 'ownership_conflicts', 'timeline_gaps', 'misrepresentation_indicators']}\n",
      "SAMPLE_COMPACT_CLAIMS: [\n",
      "  {\n",
      "    \"id\": \"clm_1\",\n",
      "    \"type\": null,\n",
      "    \"text\": null,\n",
      "    \"confidence\": 0.9,\n",
      "    \"evidence_ids\": [\n",
      "      \"ev_a695f38973\"\n",
      "    ],\n",
      "    \"entity_refs\": [],\n",
      "    \"when\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"clm_2\",\n",
      "    \"type\": null,\n",
      "    \"text\": null,\n",
      "    \"confidence\": 0.5,\n",
      "    \"evidence_ids\": [\n",
      "      \"ev_c1e447dcfe\"\n",
      "    ],\n",
      "    \"entity_refs\": [],\n",
      "    \"when\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"clm_3\",\n",
      "    \"type\": null,\n",
      "    \"text\": null,\n",
      "    \"confidence\": 0.5,\n",
      "    \"evidence_ids\": [\n",
      "      \"ev_c1e447dcfe\"\n",
      "    ],\n",
      "    \"entity_refs\": [],\n",
      "    \"when\": null\n",
      "  }\n",
      "]\n",
      "SAMPLE_EVID_SNIPS: [\n",
      "  [\n",
      "    \"ev_a695f38973\",\n",
      "    {\n",
      "      \"title\": \"Elizabeth Holmes | Biography, Net Worth, Theranos, Scandal, & Facts\",\n",
      "      \"url\": \"https://www.britannica.com/biography/Elizabeth-Holmes\",\n",
      "      \"snippet\": \"Elizabeth Holmes (born February 3, 1984, Washington, D.C., U.S.) is an American entrepreneur who was the founder and CEO (2003\\u201318) of the blood-testing company Theranos Inc. In 2014\\u2014at age 30\\u2014she was dubbed the world\\u2019s youngest self-made female billionaire, but, less than a year later, it was her own blood that authorities were after, as the nature\"\n",
      "    }\n",
      "  ],\n",
      "  [\n",
      "    \"ev_c1e447dcfe\",\n",
      "    {\n",
      "      \"title\": \"Elizabeth Holmes of Theranos, from young billionaire to prison inmate\",\n",
      "      \"url\": \"https://www.idnfinancials.com/news/56564/elizabeth-holmes-of-theranos-from-young-billionaire-to-prison-inmate\",\n",
      "      \"snippet\": \"English \\n\\nEnglish   Indonesian   \\u65e5\\u672c\\u8a9e\\n\\nLogin\\n\\n Home\\n Companies\\n News\\n Videos\\n Tools\\n\\n  Market Hints Bonds Call People Net Foreign Valuable Stock\\n Foreign Exchange Rates\\n Business Info\\n Subscribe\\n\\nSelect Language!\\n\\nEnglish \\n\\nEnglish   Indonesian   \\u65e5\\u672c\\u8a9e\\n\\nIDR / USD: ---- \\n\\nAs of:\\n\\n## Elizabeth Holmes of Theranos, from young billionaire to prison inmate\\n\"\n",
      "    }\n",
      "  ]\n",
      "]\n",
      "TOPICS_TO_WORK: ['professional_timeline', 'legal_regulatory', 'risk_inconsistencies']\n",
      "MISSING_FIELDS: {'identity': [], 'professional_timeline': ['employers', 'role_dates'], 'legal_regulatory': ['civil_cases', 'regulatory_actions', 'sanctions_list_mentions', 'court_involvement'], 'risk_inconsistencies': ['identity_conflicts', 'employment_conflicts', 'ownership_conflicts', 'timeline_gaps', 'misrepresentation_indicators']}\n",
      "SAMPLE_COMPACT_CLAIMS: [\n",
      "  {\n",
      "    \"id\": \"clm_1\",\n",
      "    \"type\": null,\n",
      "    \"text\": null,\n",
      "    \"confidence\": 0.9,\n",
      "    \"evidence_ids\": [\n",
      "      \"ev_5aea0d9b4c\"\n",
      "    ],\n",
      "    \"entity_refs\": [],\n",
      "    \"when\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"clm_2\",\n",
      "    \"type\": null,\n",
      "    \"text\": null,\n",
      "    \"confidence\": 0.9,\n",
      "    \"evidence_ids\": [\n",
      "      \"ev_b33160cd2c\"\n",
      "    ],\n",
      "    \"entity_refs\": [],\n",
      "    \"when\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"clm_3\",\n",
      "    \"type\": null,\n",
      "    \"text\": null,\n",
      "    \"confidence\": 0.9,\n",
      "    \"evidence_ids\": [\n",
      "      \"ev_b33160cd2c\"\n",
      "    ],\n",
      "    \"entity_refs\": [],\n",
      "    \"when\": null\n",
      "  }\n",
      "]\n",
      "SAMPLE_EVID_SNIPS: [\n",
      "  [\n",
      "    \"ev_5aea0d9b4c\",\n",
      "    {\n",
      "      \"title\": \"Timeline: Rise and fall of Theranos after founder Elizabeth Holmes ...\",\n",
      "      \"url\": \"https://abc7chicago.com/post/theranos-elizabeth-holmes-sunny-balwani-timeline/12028165/\",\n",
      "      \"snippet\": \"### September 2009: Ramesh \\\"Sunny\\\" Balwani joins Theranos\\n\\nBalwani guarantees a $10 million loan to Theranos and soon after takes on a formal role at the startup. Balwani, roughly 20 years older than Holmes, first met her in 2002 through a program in Beijing to learn Mandarin. Balwani had enjoyed a successful career in the software industry, and fo\"\n",
      "    }\n",
      "  ],\n",
      "  [\n",
      "    \"ev_b33160cd2c\",\n",
      "    {\n",
      "      \"title\": \"The rise and fall of Elizabeth Holmes: A timeline | CNN Business\",\n",
      "      \"url\": \"https://www.cnn.com/2022/01/04/tech/elizabeth-holmes-rise-and-fall\",\n",
      "      \"snippet\": \"Here are the highlights of the rise and fall of Elizabeth Holmes and Theranos.\\n\\n## March 2004: Holmes drops out of Stanford to pursue Theranos\\n\\nHolmes, a Stanford University sophomore studying chemical engineering, drops out of school to pursue her startup, Theranos, which she founded in 2003 at age 19. The name is a combination of the words \\u201cthera\"\n",
      "    }\n",
      "  ]\n",
      "]\n",
      "TOPICS_TO_WORK: ['legal_regulatory', 'risk_inconsistencies']\n",
      "MISSING_FIELDS: {'identity': [], 'professional_timeline': [], 'legal_regulatory': ['sanctions_list_mentions'], 'risk_inconsistencies': ['identity_conflicts', 'employment_conflicts', 'ownership_conflicts', 'timeline_gaps', 'misrepresentation_indicators']}\n",
      "SAMPLE_COMPACT_CLAIMS: [\n",
      "  {\n",
      "    \"id\": \"clm_1\",\n",
      "    \"type\": null,\n",
      "    \"text\": null,\n",
      "    \"confidence\": 0.9,\n",
      "    \"evidence_ids\": [\n",
      "      \"ev_6316137503\"\n",
      "    ],\n",
      "    \"entity_refs\": [],\n",
      "    \"when\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"clm_2\",\n",
      "    \"type\": null,\n",
      "    \"text\": null,\n",
      "    \"confidence\": 0.9,\n",
      "    \"evidence_ids\": [\n",
      "      \"ev_6316137503\"\n",
      "    ],\n",
      "    \"entity_refs\": [],\n",
      "    \"when\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"clm_3\",\n",
      "    \"type\": null,\n",
      "    \"text\": null,\n",
      "    \"confidence\": 0.8,\n",
      "    \"evidence_ids\": [\n",
      "      \"ev_ddc8b4ab5e\"\n",
      "    ],\n",
      "    \"entity_refs\": [],\n",
      "    \"when\": null\n",
      "  }\n",
      "]\n",
      "SAMPLE_EVID_SNIPS: [\n",
      "  [\n",
      "    \"ev_6316137503\",\n",
      "    {\n",
      "      \"title\": \"Elizabeth Holmes & the Theranos case: History of a fraud scandal\",\n",
      "      \"url\": \"https://www.integrityline.com/expertise/blog/elizabeth-holmes-theranos/\",\n",
      "      \"snippet\": \"Walgreens and other partners sued Theranos and the case ended in a settlement in 2017. In early 2018, the SEC announced charges against Elizabeth Holmes and her business partner Balwani. Holmes had to resign from her position as CEO and she was banned from running a publicly traded company for the next ten years. In June 2018, California law enforc\"\n",
      "    }\n",
      "  ],\n",
      "  [\n",
      "    \"ev_ddc8b4ab5e\",\n",
      "    {\n",
      "      \"title\": \"The rise and fall of Elizabeth Holmes: A timeline | CNN Business\",\n",
      "      \"url\": \"https://www.cnn.com/2022/01/04/tech/elizabeth-holmes-rise-and-fall\",\n",
      "      \"snippet\": \"Here are the highlights of the rise and fall of Elizabeth Holmes and Theranos.\\n\\n## March 2004: Holmes drops out of Stanford to pursue Theranos\\n\\nHolmes, a Stanford University sophomore studying chemical engineering, drops out of school to pursue her startup, Theranos, which she founded in 2003 at age 19. The name is a combination of the words \\u201cthera\"\n",
      "    }\n",
      "  ]\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'case_id': 'case_theranos_holmes', 'target': 'Elizabeth Holmes', 'canonical_name': 'Elizabeth Holmes', 'runtime_s': 564.4446511268616, 'structural': {'topics': {'identity': {'status': 'complete', 'missing_fields': [], 'required_fields': ['name_variants', 'date_of_birth', 'nationalities', 'general_location', 'associated_orgs'], 'field_coverage': 1.0, 'evidence_ids_total': 6, 'good_evidence_ids': 6, 'min_credibility': 0.0}, 'professional_timeline': {'status': 'complete', 'missing_fields': [], 'required_fields': ['roles', 'employers', 'board_positions', 'education', 'role_dates'], 'field_coverage': 1.0, 'evidence_ids_total': 4, 'good_evidence_ids': 4, 'min_credibility': 0.0}, 'legal_regulatory': {'status': 'complete', 'missing_fields': [], 'required_fields': ['criminal_records', 'civil_cases', 'regulatory_actions', 'sanctions_list_mentions', 'court_involvement'], 'field_coverage': 1.0, 'evidence_ids_total': 5, 'good_evidence_ids': 5, 'min_credibility': 0.0}, 'risk_inconsistencies': {'status': 'unstarted', 'missing_fields': ['identity_conflicts', 'employment_conflicts', 'ownership_conflicts', 'timeline_gaps', 'misrepresentation_indicators'], 'required_fields': ['identity_conflicts', 'employment_conflicts', 'ownership_conflicts', 'timeline_gaps', 'misrepresentation_indicators'], 'field_coverage': 0.0, 'evidence_ids_total': 0, 'good_evidence_ids': 0, 'min_credibility': 0.0}}, 'overall': {'topics_complete': 3, 'topics_total': 4, 'field_coverage_avg': 0.75, 'distinct_source_urls': 40}}, 'expected_field_hits': {'identity': {'name_variants': False, 'date_of_birth': True, 'nationalities': True, 'general_location': True, 'associated_orgs': True}, 'professional_timeline': {'employers': True, 'education': True, 'roles': True}, 'legal_regulatory': {'criminal_records': True, 'civil_cases': True, 'court_roles': False}, 'risk_inconsistencies': {'misrepresentation_indicators': False, 'timeline_gaps': False, 'identity_conflicts': None, 'employment_conflicts': None, 'ownership_conflicts': None}}, 'baseline_fact_hits': [{'id': 'eh_theranos_founder', 'covered': True, 'partial_score': 1.0}, {'id': 'eh_conviction_fraud', 'covered': False, 'partial_score': 0.0}, {'id': 'eh_blood_testing_claims', 'covered': False, 'partial_score': 0.0}], 'llm_judge': {'facts': [{'id': 'eh_theranos_founder', 'covered': True, 'confidence': 0.9, 'evidence_in_report': '2003–2018: Theranos — Founder and CEO'}, {'id': 'eh_conviction_fraud', 'covered': True, 'confidence': 0.8, 'evidence_in_report': 'Guilty of criminal fraud on four counts'}, {'id': 'eh_blood_testing_claims', 'covered': False, 'confidence': 0.0, 'evidence_in_report': ''}], 'overall_score': 0.57}, 'report_text': \"TARGET: Elizabeth Holmes\\n\\nTOPIC: identity\\nstatus: complete\\n- name_variants: ['Elizabeth Anne Holmes']\\n- date_of_birth: ['February 3, 1984']\\n- nationalities: ['American']\\n- general_location: ['California, United States']\\n- associated_orgs: ['Theranos']\\n\\nTOPIC: professional_timeline\\nstatus: complete\\n- roles: ['2003–2018: Theranos — Founder and CEO']\\n- employers: ['Theranos']\\n- board_positions: ['Harvard Medical School’s Board of Fellows']\\n- education: ['Stanford University (2002-2004)']\\n- role_dates: ['2003–2018: Theranos — Founder and CEO']\\n\\nTOPIC: legal_regulatory\\nstatus: complete\\n- criminal_records: ['Guilty of criminal fraud on four counts']\\n- civil_cases: ['Theranos ABC lawsuit for unpaid promissory notes']\\n- regulatory_actions: ['SEC charges for fraud']\\n- sanctions_list_mentions: ['Elizabeth Holmes was banned from running a publicly traded company for ten years as part of a settlement with the SEC in 2018.']\\n- court_involvement: ['United States v. Elizabeth Holmes']\\n\\nTOPIC: risk_inconsistencies\\nstatus: unstarted\\n- identity_conflicts: []\\n- employment_conflicts: []\\n- ownership_conflicts: []\\n- timeline_gaps: []\\n- misrepresentation_indicators: []\"}\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for c in cases[:1]:\n",
    "    print(f\"\\n=== Running {c.get('id')} :: {c.get('target')} ===\")\n",
    "    try:\n",
    "        res = run_case(c, llm_reason, llm_extract, llm_judge, allowed_topics=allowed_topics)\n",
    "    except Exception as e:\n",
    "        res = {\"case_id\": c.get(\"id\"), \"target\": c.get(\"target\"), \"error\": str(e)}\n",
    "    results.append(res)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d0d6965",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TARGET: Elizabeth Holmes',\n",
       " \"TOPIC: identity\\nstatus: complete\\n- name_variants: ['Elizabeth Anne Holmes']\\n- date_of_birth: ['February 3, 1984']\\n- nationalities: ['American']\\n- general_location: ['California, United States']\\n- associated_orgs: ['Theranos']\",\n",
       " \"TOPIC: professional_timeline\\nstatus: complete\\n- roles: ['2003–2018: Theranos — Founder and CEO']\\n- employers: ['Theranos']\\n- board_positions: ['Harvard Medical School’s Board of Fellows']\\n- education: ['Stanford University (2002-2004)']\\n- role_dates: ['2003–2018: Theranos — Founder and CEO']\",\n",
       " \"TOPIC: legal_regulatory\\nstatus: complete\\n- criminal_records: ['Guilty of criminal fraud on four counts']\\n- civil_cases: ['Theranos ABC lawsuit for unpaid promissory notes']\\n- regulatory_actions: ['SEC charges for fraud']\\n- sanctions_list_mentions: ['Elizabeth Holmes was banned from running a publicly traded company for ten years as part of a settlement with the SEC in 2018.']\\n- court_involvement: ['United States v. Elizabeth Holmes']\",\n",
       " 'TOPIC: risk_inconsistencies\\nstatus: unstarted\\n- identity_conflicts: []\\n- employment_conflicts: []\\n- ownership_conflicts: []\\n- timeline_gaps: []\\n- misrepresentation_indicators: []']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['report_text'].split('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0e7e2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wrote: eval_results.json\n",
      "- case_theranos_holmes: judge=0.57 coverage=0.75 runtime=564.4s\n"
     ]
    }
   ],
   "source": [
    "out_data = {\"evalset_version\": evalset_data.get(\"version\"), \"results\": results}\n",
    "with open(out, \"w\") as f:\n",
    "    json.dump(out_data, f, indent=2)\n",
    "\n",
    "print(f\"\\nWrote: {out}\")\n",
    "\n",
    "for r in results:\n",
    "    if r.get(\"error\"):\n",
    "        print(f\"- {r['case_id']}: ERROR {r['error']}\")\n",
    "        continue\n",
    "    overall = (r.get(\"llm_judge\") or {}).get(\"overall_score\", 0.0)\n",
    "    runtime = r.get(\"runtime_s\", 0.0)\n",
    "    cov = ((r.get(\"structural\") or {}).get(\"overall\") or {}).get(\"field_coverage_avg\", 0.0)\n",
    "    print(f\"- {r['case_id']}: judge={overall} coverage={cov:.2f} runtime={runtime:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "606546bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out, \"w\") as f:\n",
    "    json.dump(out_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d540f80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eval_results.json'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34d57fc7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'evalset_version': '1.0',\n",
       " 'results': [{'case_id': 'case_theranos_holmes',\n",
       "   'target': 'Elizabeth Holmes',\n",
       "   'canonical_name': 'Elizabeth Holmes',\n",
       "   'runtime_s': 564.4446511268616,\n",
       "   'structural': {'topics': {'identity': {'status': 'complete',\n",
       "      'missing_fields': [],\n",
       "      'required_fields': ['name_variants',\n",
       "       'date_of_birth',\n",
       "       'nationalities',\n",
       "       'general_location',\n",
       "       'associated_orgs'],\n",
       "      'field_coverage': 1.0,\n",
       "      'evidence_ids_total': 6,\n",
       "      'good_evidence_ids': 6,\n",
       "      'min_credibility': 0.0},\n",
       "     'professional_timeline': {'status': 'complete',\n",
       "      'missing_fields': [],\n",
       "      'required_fields': ['roles',\n",
       "       'employers',\n",
       "       'board_positions',\n",
       "       'education',\n",
       "       'role_dates'],\n",
       "      'field_coverage': 1.0,\n",
       "      'evidence_ids_total': 4,\n",
       "      'good_evidence_ids': 4,\n",
       "      'min_credibility': 0.0},\n",
       "     'legal_regulatory': {'status': 'complete',\n",
       "      'missing_fields': [],\n",
       "      'required_fields': ['criminal_records',\n",
       "       'civil_cases',\n",
       "       'regulatory_actions',\n",
       "       'sanctions_list_mentions',\n",
       "       'court_involvement'],\n",
       "      'field_coverage': 1.0,\n",
       "      'evidence_ids_total': 5,\n",
       "      'good_evidence_ids': 5,\n",
       "      'min_credibility': 0.0},\n",
       "     'risk_inconsistencies': {'status': 'unstarted',\n",
       "      'missing_fields': ['identity_conflicts',\n",
       "       'employment_conflicts',\n",
       "       'ownership_conflicts',\n",
       "       'timeline_gaps',\n",
       "       'misrepresentation_indicators'],\n",
       "      'required_fields': ['identity_conflicts',\n",
       "       'employment_conflicts',\n",
       "       'ownership_conflicts',\n",
       "       'timeline_gaps',\n",
       "       'misrepresentation_indicators'],\n",
       "      'field_coverage': 0.0,\n",
       "      'evidence_ids_total': 0,\n",
       "      'good_evidence_ids': 0,\n",
       "      'min_credibility': 0.0}},\n",
       "    'overall': {'topics_complete': 3,\n",
       "     'topics_total': 4,\n",
       "     'field_coverage_avg': 0.75,\n",
       "     'distinct_source_urls': 40}},\n",
       "   'expected_field_hits': {'identity': {'name_variants': False,\n",
       "     'date_of_birth': True,\n",
       "     'nationalities': True,\n",
       "     'general_location': True,\n",
       "     'associated_orgs': True},\n",
       "    'professional_timeline': {'employers': True,\n",
       "     'education': True,\n",
       "     'roles': True},\n",
       "    'legal_regulatory': {'criminal_records': True,\n",
       "     'civil_cases': True,\n",
       "     'court_roles': False},\n",
       "    'risk_inconsistencies': {'misrepresentation_indicators': False,\n",
       "     'timeline_gaps': False,\n",
       "     'identity_conflicts': None,\n",
       "     'employment_conflicts': None,\n",
       "     'ownership_conflicts': None}},\n",
       "   'baseline_fact_hits': [{'id': 'eh_theranos_founder',\n",
       "     'covered': True,\n",
       "     'partial_score': 1.0},\n",
       "    {'id': 'eh_conviction_fraud', 'covered': False, 'partial_score': 0.0},\n",
       "    {'id': 'eh_blood_testing_claims', 'covered': False, 'partial_score': 0.0}],\n",
       "   'llm_judge': {'facts': [{'id': 'eh_theranos_founder',\n",
       "      'covered': True,\n",
       "      'confidence': 0.9,\n",
       "      'evidence_in_report': '2003–2018: Theranos — Founder and CEO'},\n",
       "     {'id': 'eh_conviction_fraud',\n",
       "      'covered': True,\n",
       "      'confidence': 0.8,\n",
       "      'evidence_in_report': 'Guilty of criminal fraud on four counts'},\n",
       "     {'id': 'eh_blood_testing_claims',\n",
       "      'covered': False,\n",
       "      'confidence': 0.0,\n",
       "      'evidence_in_report': ''}],\n",
       "    'overall_score': 0.57},\n",
       "   'report_text': \"TARGET: Elizabeth Holmes\\n\\nTOPIC: identity\\nstatus: complete\\n- name_variants: ['Elizabeth Anne Holmes']\\n- date_of_birth: ['February 3, 1984']\\n- nationalities: ['American']\\n- general_location: ['California, United States']\\n- associated_orgs: ['Theranos']\\n\\nTOPIC: professional_timeline\\nstatus: complete\\n- roles: ['2003–2018: Theranos — Founder and CEO']\\n- employers: ['Theranos']\\n- board_positions: ['Harvard Medical School’s Board of Fellows']\\n- education: ['Stanford University (2002-2004)']\\n- role_dates: ['2003–2018: Theranos — Founder and CEO']\\n\\nTOPIC: legal_regulatory\\nstatus: complete\\n- criminal_records: ['Guilty of criminal fraud on four counts']\\n- civil_cases: ['Theranos ABC lawsuit for unpaid promissory notes']\\n- regulatory_actions: ['SEC charges for fraud']\\n- sanctions_list_mentions: ['Elizabeth Holmes was banned from running a publicly traded company for ten years as part of a settlement with the SEC in 2018.']\\n- court_involvement: ['United States v. Elizabeth Holmes']\\n\\nTOPIC: risk_inconsistencies\\nstatus: unstarted\\n- identity_conflicts: []\\n- employment_conflicts: []\\n- ownership_conflicts: []\\n- timeline_gaps: []\\n- misrepresentation_indicators: []\"}]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b1105f9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running case_ftx_sbf :: Sam Bankman-Fried ===\n",
      "topics_to_work: ['risk_inconsistencies', 'identity', 'professional_timeline', 'legal_regulatory']\n",
      "planned queries: 6\n",
      "  - Sam Bankman-Fried date of birth | {'kind': 'topic', 'topic': 'identity'} | date_of_birth\n",
      "  - Sam Bankman-Fried nationalities | {'kind': 'topic', 'topic': 'identity'} | nationalities\n",
      "  - Sam Bankman-Fried associated organizations | {'kind': 'topic', 'topic': 'identity'} | associated_orgs\n",
      "  - Sam Bankman-Fried professional roles | {'kind': 'topic', 'topic': 'professional_timeline'} | roles\n",
      "  - Sam Bankman-Fried criminal records | {'kind': 'topic', 'topic': 'legal_regulatory'} | criminal_records\n",
      "  - Sam Bankman-Fried regulatory actions | {'kind': 'topic', 'topic': 'legal_regulatory'} | regulatory_actions\n",
      "TOPICS_TO_WORK: ['risk_inconsistencies', 'identity', 'professional_timeline', 'legal_regulatory']\n",
      "MISSING_FIELDS: {'identity': ['name_variants', 'date_of_birth', 'nationalities', 'general_location', 'associated_orgs'], 'professional_timeline': ['roles', 'employers', 'board_positions', 'education', 'role_dates'], 'legal_regulatory': ['criminal_records', 'civil_cases', 'regulatory_actions', 'sanctions_list_mentions', 'court_involvement'], 'risk_inconsistencies': ['identity_conflicts', 'employment_conflicts', 'ownership_conflicts', 'timeline_gaps', 'misrepresentation_indicators']}\n",
      "SAMPLE_COMPACT_CLAIMS: [\n",
      "  {\n",
      "    \"id\": \"clm_1\",\n",
      "    \"type\": null,\n",
      "    \"text\": null,\n",
      "    \"confidence\": 0.9,\n",
      "    \"evidence_ids\": [\n",
      "      \"ev_b2d16df7f1\"\n",
      "    ],\n",
      "    \"entity_refs\": [],\n",
      "    \"when\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"clm_2\",\n",
      "    \"type\": null,\n",
      "    \"text\": null,\n",
      "    \"confidence\": 0.8,\n",
      "    \"evidence_ids\": [\n",
      "      \"ev_b2d16df7f1\"\n",
      "    ],\n",
      "    \"entity_refs\": [],\n",
      "    \"when\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"clm_3\",\n",
      "    \"type\": null,\n",
      "    \"text\": null,\n",
      "    \"confidence\": 0.9,\n",
      "    \"evidence_ids\": [\n",
      "      \"ev_d455fa1c4f\"\n",
      "    ],\n",
      "    \"entity_refs\": [],\n",
      "    \"when\": null\n",
      "  }\n",
      "]\n",
      "SAMPLE_EVID_SNIPS: [\n",
      "  [\n",
      "    \"ev_b2d16df7f1\",\n",
      "    {\n",
      "      \"title\": \"Sam Bankman-Fried's downfall is more than a black eye for Effective ...\",\n",
      "      \"url\": \"https://philanthropydaily.com/sam-bankman-frieds-downfall-is-more-than-a-black-eye-for-effective-altruism/\",\n",
      "      \"snippet\": \"#### SBF AND EA\\n\\nWhat makes Bankman-Fried\\u2019s downfall more than just a black eye for EA is his very real connection to the EA movement, particularly with William MacAskill. MacAskill is a Scottish philosopher at the University of Oxford. He co-founded Giving What We Can, an EA-associated organization that asks its members, many of them middle income\"\n",
      "    }\n",
      "  ],\n",
      "  [\n",
      "    \"ev_d455fa1c4f\",\n",
      "    {\n",
      "      \"title\": \"Sam Bankman-Fried - InfluenceWatch\",\n",
      "      \"url\": \"https://www.influencewatch.org/person/sam-bankman-fried/\",\n",
      "      \"snippet\": \"Sam Bankman-Fried is an American-born investor and entrepreneur. He was the founder of FTX, a cryptocurrency futures exchange based out of Hong Kong. He also founded the digital currency trading firm Alameda Research. In 2021, leading business publication Forbes estimated that Bankman-Fried has a net worth of at least $16 billion. Yahoo Finance has\"\n",
      "    }\n",
      "  ]\n",
      "]\n",
      "topics_to_work: ['risk_inconsistencies', 'identity', 'professional_timeline', 'legal_regulatory']\n",
      "lead_to_work: Verify Sam Bankman-Fried's involvement with Effective Altruism | p= 0.7 depth= 1\n",
      "planned queries: 6\n",
      "  - Sam Bankman-Fried name variants | {'kind': 'topic', 'topic': 'identity'} | name_variants\n",
      "  - Sam Bankman-Fried general location | {'kind': 'topic', 'topic': 'identity'} | general_location\n",
      "  - Sam Bankman-Fried education history | {'kind': 'topic', 'topic': 'professional_timeline'} | education\n",
      "  - Sam Bankman-Fried board positions | {'kind': 'topic', 'topic': 'professional_timeline'} | board_positions\n",
      "  - Sam Bankman-Fried civil cases | {'kind': 'topic', 'topic': 'legal_regulatory'} | civil_cases\n",
      "  - Sam Bankman-Fried court involvement | {'kind': 'topic', 'topic': 'legal_regulatory'} | court_involvement\n",
      "TOPICS_TO_WORK: ['risk_inconsistencies', 'identity', 'professional_timeline', 'legal_regulatory']\n",
      "MISSING_FIELDS: {'identity': ['name_variants', 'nationalities', 'general_location'], 'professional_timeline': ['employers', 'board_positions', 'education', 'role_dates'], 'legal_regulatory': ['civil_cases', 'sanctions_list_mentions', 'court_involvement'], 'risk_inconsistencies': ['identity_conflicts', 'employment_conflicts', 'ownership_conflicts', 'timeline_gaps', 'misrepresentation_indicators']}\n",
      "SAMPLE_COMPACT_CLAIMS: [\n",
      "  {\n",
      "    \"id\": \"clm_1\",\n",
      "    \"type\": null,\n",
      "    \"text\": null,\n",
      "    \"confidence\": 1.0,\n",
      "    \"evidence_ids\": [\n",
      "      \"ev_fd77d9e85a\"\n",
      "    ],\n",
      "    \"entity_refs\": [],\n",
      "    \"when\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"clm_2\",\n",
      "    \"type\": null,\n",
      "    \"text\": null,\n",
      "    \"confidence\": 1.0,\n",
      "    \"evidence_ids\": [\n",
      "      \"ev_fd77d9e85a\"\n",
      "    ],\n",
      "    \"entity_refs\": [],\n",
      "    \"when\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"clm_3\",\n",
      "    \"type\": null,\n",
      "    \"text\": null,\n",
      "    \"confidence\": 1.0,\n",
      "    \"evidence_ids\": [\n",
      "      \"ev_6d7548d542\"\n",
      "    ],\n",
      "    \"entity_refs\": [],\n",
      "    \"when\": null\n",
      "  }\n",
      "]\n",
      "SAMPLE_EVID_SNIPS: [\n",
      "  [\n",
      "    \"ev_fd77d9e85a\",\n",
      "    {\n",
      "      \"title\": \"Sam Bankman-Fried - FTX, Education, Conviction, & Prison\",\n",
      "      \"url\": \"https://www.britannica.com/money/Sam-Bankman-Fried\",\n",
      "      \"snippet\": \"Sam Bankman-Fried (born March 6, 1992, Stanford, California, U.S.) was the founder and former chief executive officer (2019\\u201322) of FTX Trading Ltd., a cryptocurrency exchange. The exchange became the second largest of its kind, making Bankman-Fried a powerful figure within the market of digital assets and in discussions in the United States Congres\"\n",
      "    }\n",
      "  ],\n",
      "  [\n",
      "    \"ev_6d7548d542\",\n",
      "    {\n",
      "      \"title\": \"Sam Bankman-Fried\",\n",
      "      \"url\": \"https://www.influencewatch.org/person/sam-bankman-fried/\",\n",
      "      \"snippet\": \"Sam Bankman-Fried is an American-born investor and entrepreneur. He was the founder of FTX, a cryptocurrency futures exchange based out of Hong Kong. He also founded the digital currency trading firm Alameda Research. In 2021, leading business publication Forbes estimated that Bankman-Fried has a net worth of at least $16 billion. Yahoo Finance has\"\n",
      "    }\n",
      "  ]\n",
      "]\n",
      "topics_to_work: ['risk_inconsistencies', 'professional_timeline', 'legal_regulatory']\n",
      "lead_to_work: Investigate Sam Bankman-Fried's legal and regulatory issues | p= 0.7 depth= 1\n",
      "planned queries: 6\n",
      "  - Sam Bankman-Fried employment history | {'kind': 'topic', 'topic': 'professional_timeline'} | employers\n",
      "  - Sam Bankman-Fried ownership conflicts FTX | {'kind': 'topic', 'topic': 'risk_inconsistencies'} | ownership_conflicts\n",
      "  - Sam Bankman-Fried timeline gaps in career | {'kind': 'topic', 'topic': 'risk_inconsistencies'} | timeline_gaps\n",
      "  - Sam Bankman-Fried misrepresentation indicators | {'kind': 'topic', 'topic': 'risk_inconsistencies'} | misrepresentation_indicators\n",
      "  - Sam Bankman-Fried sanctions list mentions | {'kind': 'topic', 'topic': 'legal_regulatory'} | sanctions_list_mentions\n",
      "  - Sam Bankman-Fried identity conflicts | {'kind': 'topic', 'topic': 'risk_inconsistencies'} | identity_conflicts\n",
      "TOPICS_TO_WORK: ['risk_inconsistencies', 'professional_timeline', 'legal_regulatory']\n",
      "MISSING_FIELDS: {'identity': [], 'professional_timeline': ['employers', 'board_positions', 'education', 'role_dates'], 'legal_regulatory': ['civil_cases', 'sanctions_list_mentions', 'court_involvement'], 'risk_inconsistencies': ['identity_conflicts', 'employment_conflicts', 'ownership_conflicts', 'timeline_gaps', 'misrepresentation_indicators']}\n",
      "SAMPLE_COMPACT_CLAIMS: [\n",
      "  {\n",
      "    \"id\": \"clm_1\",\n",
      "    \"type\": null,\n",
      "    \"text\": null,\n",
      "    \"confidence\": 0.9,\n",
      "    \"evidence_ids\": [\n",
      "      \"ev_8475bbb47a\"\n",
      "    ],\n",
      "    \"entity_refs\": [],\n",
      "    \"when\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"clm_2\",\n",
      "    \"type\": null,\n",
      "    \"text\": null,\n",
      "    \"confidence\": 0.9,\n",
      "    \"evidence_ids\": [\n",
      "      \"ev_8475bbb47a\"\n",
      "    ],\n",
      "    \"entity_refs\": [],\n",
      "    \"when\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"clm_3\",\n",
      "    \"type\": null,\n",
      "    \"text\": null,\n",
      "    \"confidence\": 0.9,\n",
      "    \"evidence_ids\": [\n",
      "      \"ev_8475bbb47a\"\n",
      "    ],\n",
      "    \"entity_refs\": [],\n",
      "    \"when\": null\n",
      "  }\n",
      "]\n",
      "SAMPLE_EVID_SNIPS: [\n",
      "  [\n",
      "    \"ev_8475bbb47a\",\n",
      "    {\n",
      "      \"title\": \"A timeline of Sam Bankman-Fried, who could go down as one of ...\",\n",
      "      \"url\": \"https://finance.yahoo.com/news/timeline-sam-bankman-fried-could-113000558.html\",\n",
      "      \"snippet\": \"2010\\u20132014: Bankman-Fried attends MIT, the Massachusetts Institute of Technology, in 2010 after flipping a coin to decide between it and Cal Tech. He majors in physics in college and earns a minor in math. Despite his natural intelligence, SBF is less interested in his classes than he is in hanging out with friends in the Epsilon Theta fraternity, w\"\n",
      "    }\n",
      "  ],\n",
      "  [\n",
      "    \"ev_f9b5308c84\",\n",
      "    {\n",
      "      \"title\": \"A timeline of Sam Bankman-Fried, who could go down as ... - Fortune\",\n",
      "      \"url\": \"https://fortune.com/crypto/2023/09/28/sam-bankman-fried-trial-timeline-ftx-alameda-research/\",\n",
      "      \"snippet\": \"2010\\u20132014: Bankman-Fried attends MIT, the Massachusetts Institute of Technology, in 2010 after flipping a coin to decide between it and Cal Tech. He majors in physics in college and earns a minor in math. Despite his natural intelligence, SBF is less interested in his classes than he is in hanging out with friends in the Epsilon Theta fraternity, w\"\n",
      "    }\n",
      "  ]\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topics_to_work: ['risk_inconsistencies', 'professional_timeline', 'legal_regulatory']\n",
      "lead_to_work: Examine the legal implications of CFTC charges against Sam Bankman-Fried | p= 0.8 depth= 1\n",
      "planned queries: 6\n",
      "  - Sam Bankman-Fried employment conflicts FTX | {'kind': 'topic', 'topic': 'risk_inconsistencies'} | employment_conflicts\n",
      "  - Sam Bankman-Fried ownership conflicts Alameda Research | {'kind': 'topic', 'topic': 'risk_inconsistencies'} | ownership_conflicts\n",
      "  - Sam Bankman-Fried role dates at Alameda Research | {'kind': 'topic', 'topic': 'professional_timeline'} | role_dates\n",
      "  - Sam Bankman-Fried civil cases details | {'kind': 'topic', 'topic': 'legal_regulatory'} | civil_cases\n",
      "  - Sam Bankman-Fried sanctions list mentions 2023 | {'kind': 'topic', 'topic': 'legal_regulatory'} | sanctions_list_mentions\n",
      "  - CFTC charges implications for Sam Bankman-Fried | {'kind': 'lead', 'lead_id': 'lead_2b121d1b6f'} | verification\n",
      "TOPICS_TO_WORK: ['risk_inconsistencies', 'professional_timeline', 'legal_regulatory']\n",
      "MISSING_FIELDS: {'identity': [], 'professional_timeline': ['employers', 'board_positions', 'role_dates'], 'legal_regulatory': ['civil_cases', 'sanctions_list_mentions'], 'risk_inconsistencies': ['identity_conflicts', 'employment_conflicts', 'ownership_conflicts', 'timeline_gaps', 'misrepresentation_indicators']}\n",
      "SAMPLE_COMPACT_CLAIMS: [\n",
      "  {\n",
      "    \"id\": \"clm_1\",\n",
      "    \"type\": null,\n",
      "    \"text\": null,\n",
      "    \"confidence\": 0.9,\n",
      "    \"evidence_ids\": [\n",
      "      \"ev_c19b611575\"\n",
      "    ],\n",
      "    \"entity_refs\": [],\n",
      "    \"when\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"clm_2\",\n",
      "    \"type\": null,\n",
      "    \"text\": null,\n",
      "    \"confidence\": 0.95,\n",
      "    \"evidence_ids\": [\n",
      "      \"ev_3791bcc2d6\"\n",
      "    ],\n",
      "    \"entity_refs\": [],\n",
      "    \"when\": null\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"clm_3\",\n",
      "    \"type\": null,\n",
      "    \"text\": null,\n",
      "    \"confidence\": 0.9,\n",
      "    \"evidence_ids\": [\n",
      "      \"ev_3791bcc2d6\"\n",
      "    ],\n",
      "    \"entity_refs\": [],\n",
      "    \"when\": null\n",
      "  }\n",
      "]\n",
      "SAMPLE_EVID_SNIPS: [\n",
      "  [\n",
      "    \"ev_c19b611575\",\n",
      "    {\n",
      "      \"title\": \"Sam Bankman-Fried - Wikipedia\",\n",
      "      \"url\": \"https://en.wikipedia.org/wiki/Sam_Bankman-Fried\",\n",
      "      \"snippet\": \"Bankman-Fried is vegan. He was raised in a Jewish family. In mid-2021 it was reported that he lived with approximately 10 roommates in a five-bedroom Bahamian penthouse bought by co-CEO of FTX Ryan Salame. After FTX's collapse, the penthouse was put up for sale for close to $40 million. Bankman-Fried had a relationship with Alameda Research CEO Car\"\n",
      "    }\n",
      "  ],\n",
      "  [\n",
      "    \"ev_3791bcc2d6\",\n",
      "    {\n",
      "      \"title\": \"A timeline of Sam Bankman-Fried, who could go down as ... - Fortune\",\n",
      "      \"url\": \"https://fortune.com/crypto/2023/09/28/sam-bankman-fried-trial-timeline-ftx-alameda-research/\",\n",
      "      \"snippet\": \"2017: SBF approaches Wang, then a software engineer at Google, asking him to help create crypto trading firm Alameda Research. The company originally had $55 million under management that came from employees as well as loans from wealthy crypto investors, according to the New York Times. [...] 2014: Shortly after graduating, SBF lands a job at Wall\"\n",
      "    }\n",
      "  ]\n",
      "]\n",
      "{'case_id': 'case_ftx_sbf', 'target': 'Sam Bankman-Fried', 'canonical_name': 'Sam Bankman-Fried', 'runtime_s': 748.5857107639313, 'structural': {'topics': {'identity': {'status': 'complete', 'missing_fields': [], 'required_fields': ['name_variants', 'date_of_birth', 'nationalities', 'general_location', 'associated_orgs'], 'field_coverage': 1.0, 'evidence_ids_total': 5, 'good_evidence_ids': 5, 'min_credibility': 0.0}, 'professional_timeline': {'status': 'partial', 'missing_fields': ['board_positions'], 'required_fields': ['roles', 'employers', 'board_positions', 'education', 'role_dates'], 'field_coverage': 0.8, 'evidence_ids_total': 8, 'good_evidence_ids': 8, 'min_credibility': 0.0}, 'legal_regulatory': {'status': 'complete', 'missing_fields': [], 'required_fields': ['criminal_records', 'civil_cases', 'regulatory_actions', 'sanctions_list_mentions', 'court_involvement'], 'field_coverage': 1.0, 'evidence_ids_total': 6, 'good_evidence_ids': 6, 'min_credibility': 0.0}, 'risk_inconsistencies': {'status': 'unstarted', 'missing_fields': ['identity_conflicts', 'employment_conflicts', 'ownership_conflicts', 'timeline_gaps', 'misrepresentation_indicators'], 'required_fields': ['identity_conflicts', 'employment_conflicts', 'ownership_conflicts', 'timeline_gaps', 'misrepresentation_indicators'], 'field_coverage': 0.0, 'evidence_ids_total': 0, 'good_evidence_ids': 0, 'min_credibility': 0.0}}, 'overall': {'topics_complete': 2, 'topics_total': 4, 'field_coverage_avg': 0.7, 'distinct_source_urls': 38}}, 'expected_field_hits': {'identity': {'name_variants': True, 'date_of_birth': None, 'nationalities': True, 'general_location': False, 'associated_orgs': True}, 'professional_timeline': {'employers': True, 'roles': True, 'education': None}, 'legal_regulatory': {'criminal_records': True, 'civil_cases': True, 'court_roles': True}, 'risk_inconsistencies': {'misrepresentation_indicators': False, 'timeline_gaps': False, 'identity_conflicts': None, 'employment_conflicts': None, 'ownership_conflicts': None}}, 'baseline_fact_hits': [{'id': 'sbf_ftx_founder', 'covered': True, 'partial_score': 1.0}, {'id': 'sbf_sentenced_25_years', 'covered': False, 'partial_score': 0.0}, {'id': 'sbf_customer_funds', 'covered': False, 'partial_score': 0.0}], 'llm_judge': {'facts': [{'id': 'sbf_ftx_founder', 'covered': True, 'confidence': 0.9, 'evidence_in_report': '2019–2022: FTX — Founder and CEO'}, {'id': 'sbf_sentenced_25_years', 'covered': False, 'confidence': 0.0, 'evidence_in_report': ''}, {'id': 'sbf_customer_funds', 'covered': False, 'confidence': 0.0, 'evidence_in_report': ''}], 'overall_score': 0.3}, 'report_text': \"TARGET: Sam Bankman-Fried\\n\\nTOPIC: identity\\nstatus: complete\\n- name_variants: ['Samuel Benjamin Bankman-Fried', 'SBF']\\n- date_of_birth: ['March 6, 1992']\\n- nationalities: ['American']\\n- general_location: ['Stanford, California, U.S.']\\n- associated_orgs: ['FTX', 'Alameda Research']\\n\\nTOPIC: professional_timeline\\nstatus: partial\\n- roles: ['2019–2022: FTX — Founder and CEO', '2017: Jane Street Capital — Trader', '2019–2022: FTX Trading Ltd. — Founder and CEO', 'Co-founder of Alameda Research']\\n- employers: ['Alameda Research', 'FTX']\\n- board_positions: []\\n- education: ['2010–2014: Massachusetts Institute of Technology — Physics major, Math minor']\\n- role_dates: ['2017–2022: Alameda Research', '2019–2022: FTX']\\n\\nTOPIC: legal_regulatory\\nstatus: complete\\n- criminal_records: ['Charged with wire fraud, securities fraud, and money laundering']\\n- civil_cases: ['United States v. Samuel Bankman-Fried, 22 Cr. 673 (LAK)']\\n- regulatory_actions: ['CFTC charges for violations of the Commodity Exchange Act']\\n- sanctions_list_mentions: ['Convicted on all charges, sentencing scheduled for March 28, 2024']\\n- court_involvement: ['CFTC charges for fraud and material misrepresentations']\\n\\nTOPIC: risk_inconsistencies\\nstatus: unstarted\\n- identity_conflicts: []\\n- employment_conflicts: []\\n- ownership_conflicts: []\\n- timeline_gaps: []\\n- misrepresentation_indicators: []\"}\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for c in cases[1:2]:\n",
    "    print(f\"\\n=== Running {c.get('id')} :: {c.get('target')} ===\")\n",
    "    try:\n",
    "        res = run_case(c, llm_reason, llm_extract, llm_judge, allowed_topics=allowed_topics)\n",
    "    except Exception as e:\n",
    "        res = {\"case_id\": c.get(\"id\"), \"target\": c.get(\"target\"), \"error\": str(e)}\n",
    "    results.append(res)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "af59ea5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eval_results_2026_02_22__15_57_11.439170.json'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b0bf1cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wrote: eval_results_2026_02_22__15_57_11.439170.json\n",
      "- case_ftx_sbf: judge=0.3 coverage=0.70 runtime=748.6s\n"
     ]
    }
   ],
   "source": [
    "out_data_2 = {\"evalset_version\": evalset_data.get(\"version\"), \"results\": results}\n",
    "with open(out, \"w\") as f:\n",
    "    json.dump(out_data_2, f, indent=2)\n",
    "\n",
    "print(f\"\\nWrote: {out}\")\n",
    "\n",
    "for r in results:\n",
    "    if r.get(\"error\"):\n",
    "        print(f\"- {r['case_id']}: ERROR {r['error']}\")\n",
    "        continue\n",
    "    overall_2 = (r.get(\"llm_judge\") or {}).get(\"overall_score\", 0.0)\n",
    "    runtime_2 = r.get(\"runtime_s\", 0.0)\n",
    "    cov_2 = ((r.get(\"structural\") or {}).get(\"overall\") or {}).get(\"field_coverage_avg\", 0.0)\n",
    "    print(f\"- {r['case_id']}: judge={overall_2} coverage={cov_2:.2f} runtime={runtime_2:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "48c143b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'evalset_version': '1.0',\n",
       " 'results': [{'case_id': 'case_ftx_sbf',\n",
       "   'target': 'Sam Bankman-Fried',\n",
       "   'canonical_name': 'Sam Bankman-Fried',\n",
       "   'runtime_s': 748.5857107639313,\n",
       "   'structural': {'topics': {'identity': {'status': 'complete',\n",
       "      'missing_fields': [],\n",
       "      'required_fields': ['name_variants',\n",
       "       'date_of_birth',\n",
       "       'nationalities',\n",
       "       'general_location',\n",
       "       'associated_orgs'],\n",
       "      'field_coverage': 1.0,\n",
       "      'evidence_ids_total': 5,\n",
       "      'good_evidence_ids': 5,\n",
       "      'min_credibility': 0.0},\n",
       "     'professional_timeline': {'status': 'partial',\n",
       "      'missing_fields': ['board_positions'],\n",
       "      'required_fields': ['roles',\n",
       "       'employers',\n",
       "       'board_positions',\n",
       "       'education',\n",
       "       'role_dates'],\n",
       "      'field_coverage': 0.8,\n",
       "      'evidence_ids_total': 8,\n",
       "      'good_evidence_ids': 8,\n",
       "      'min_credibility': 0.0},\n",
       "     'legal_regulatory': {'status': 'complete',\n",
       "      'missing_fields': [],\n",
       "      'required_fields': ['criminal_records',\n",
       "       'civil_cases',\n",
       "       'regulatory_actions',\n",
       "       'sanctions_list_mentions',\n",
       "       'court_involvement'],\n",
       "      'field_coverage': 1.0,\n",
       "      'evidence_ids_total': 6,\n",
       "      'good_evidence_ids': 6,\n",
       "      'min_credibility': 0.0},\n",
       "     'risk_inconsistencies': {'status': 'unstarted',\n",
       "      'missing_fields': ['identity_conflicts',\n",
       "       'employment_conflicts',\n",
       "       'ownership_conflicts',\n",
       "       'timeline_gaps',\n",
       "       'misrepresentation_indicators'],\n",
       "      'required_fields': ['identity_conflicts',\n",
       "       'employment_conflicts',\n",
       "       'ownership_conflicts',\n",
       "       'timeline_gaps',\n",
       "       'misrepresentation_indicators'],\n",
       "      'field_coverage': 0.0,\n",
       "      'evidence_ids_total': 0,\n",
       "      'good_evidence_ids': 0,\n",
       "      'min_credibility': 0.0}},\n",
       "    'overall': {'topics_complete': 2,\n",
       "     'topics_total': 4,\n",
       "     'field_coverage_avg': 0.7,\n",
       "     'distinct_source_urls': 38}},\n",
       "   'expected_field_hits': {'identity': {'name_variants': True,\n",
       "     'date_of_birth': None,\n",
       "     'nationalities': True,\n",
       "     'general_location': False,\n",
       "     'associated_orgs': True},\n",
       "    'professional_timeline': {'employers': True,\n",
       "     'roles': True,\n",
       "     'education': None},\n",
       "    'legal_regulatory': {'criminal_records': True,\n",
       "     'civil_cases': True,\n",
       "     'court_roles': True},\n",
       "    'risk_inconsistencies': {'misrepresentation_indicators': False,\n",
       "     'timeline_gaps': False,\n",
       "     'identity_conflicts': None,\n",
       "     'employment_conflicts': None,\n",
       "     'ownership_conflicts': None}},\n",
       "   'baseline_fact_hits': [{'id': 'sbf_ftx_founder',\n",
       "     'covered': True,\n",
       "     'partial_score': 1.0},\n",
       "    {'id': 'sbf_sentenced_25_years', 'covered': False, 'partial_score': 0.0},\n",
       "    {'id': 'sbf_customer_funds', 'covered': False, 'partial_score': 0.0}],\n",
       "   'llm_judge': {'facts': [{'id': 'sbf_ftx_founder',\n",
       "      'covered': True,\n",
       "      'confidence': 0.9,\n",
       "      'evidence_in_report': '2019–2022: FTX — Founder and CEO'},\n",
       "     {'id': 'sbf_sentenced_25_years',\n",
       "      'covered': False,\n",
       "      'confidence': 0.0,\n",
       "      'evidence_in_report': ''},\n",
       "     {'id': 'sbf_customer_funds',\n",
       "      'covered': False,\n",
       "      'confidence': 0.0,\n",
       "      'evidence_in_report': ''}],\n",
       "    'overall_score': 0.3},\n",
       "   'report_text': \"TARGET: Sam Bankman-Fried\\n\\nTOPIC: identity\\nstatus: complete\\n- name_variants: ['Samuel Benjamin Bankman-Fried', 'SBF']\\n- date_of_birth: ['March 6, 1992']\\n- nationalities: ['American']\\n- general_location: ['Stanford, California, U.S.']\\n- associated_orgs: ['FTX', 'Alameda Research']\\n\\nTOPIC: professional_timeline\\nstatus: partial\\n- roles: ['2019–2022: FTX — Founder and CEO', '2017: Jane Street Capital — Trader', '2019–2022: FTX Trading Ltd. — Founder and CEO', 'Co-founder of Alameda Research']\\n- employers: ['Alameda Research', 'FTX']\\n- board_positions: []\\n- education: ['2010–2014: Massachusetts Institute of Technology — Physics major, Math minor']\\n- role_dates: ['2017–2022: Alameda Research', '2019–2022: FTX']\\n\\nTOPIC: legal_regulatory\\nstatus: complete\\n- criminal_records: ['Charged with wire fraud, securities fraud, and money laundering']\\n- civil_cases: ['United States v. Samuel Bankman-Fried, 22 Cr. 673 (LAK)']\\n- regulatory_actions: ['CFTC charges for violations of the Commodity Exchange Act']\\n- sanctions_list_mentions: ['Convicted on all charges, sentencing scheduled for March 28, 2024']\\n- court_involvement: ['CFTC charges for fraud and material misrepresentations']\\n\\nTOPIC: risk_inconsistencies\\nstatus: unstarted\\n- identity_conflicts: []\\n- employment_conflicts: []\\n- ownership_conflicts: []\\n- timeline_gaps: []\\n- misrepresentation_indicators: []\"}]}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "33f38aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "TARGET: Sam Bankman-Fried\n",
      "-----\n",
      "TOPIC: identity\n",
      "status: complete\n",
      "- name_variants: ['Samuel Benjamin Bankman-Fried', 'SBF']\n",
      "- date_of_birth: ['March 6, 1992']\n",
      "- nationalities: ['American']\n",
      "- general_location: ['Stanford, California, U.S.']\n",
      "- associated_orgs: ['FTX', 'Alameda Research']\n",
      "-----\n",
      "TOPIC: professional_timeline\n",
      "status: partial\n",
      "- roles: ['2019–2022: FTX — Founder and CEO', '2017: Jane Street Capital — Trader', '2019–2022: FTX Trading Ltd. — Founder and CEO', 'Co-founder of Alameda Research']\n",
      "- employers: ['Alameda Research', 'FTX']\n",
      "- board_positions: []\n",
      "- education: ['2010–2014: Massachusetts Institute of Technology — Physics major, Math minor']\n",
      "- role_dates: ['2017–2022: Alameda Research', '2019–2022: FTX']\n",
      "-----\n",
      "TOPIC: legal_regulatory\n",
      "status: complete\n",
      "- criminal_records: ['Charged with wire fraud, securities fraud, and money laundering']\n",
      "- civil_cases: ['United States v. Samuel Bankman-Fried, 22 Cr. 673 (LAK)']\n",
      "- regulatory_actions: ['CFTC charges for violations of the Commodity Exchange Act']\n",
      "- sanctions_list_mentions: ['Convicted on all charges, sentencing scheduled for March 28, 2024']\n",
      "- court_involvement: ['CFTC charges for fraud and material misrepresentations']\n",
      "-----\n",
      "TOPIC: risk_inconsistencies\n",
      "status: unstarted\n",
      "- identity_conflicts: []\n",
      "- employment_conflicts: []\n",
      "- ownership_conflicts: []\n",
      "- timeline_gaps: []\n",
      "- misrepresentation_indicators: []\n"
     ]
    }
   ],
   "source": [
    "for o in res['report_text'].split('\\n\\n'):\n",
    "    print('-----')\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6f79cd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "TARGET: Elizabeth Holmes\n",
      "-----\n",
      "TOPIC: identity\n",
      "status: complete\n",
      "- name_variants: ['Elizabeth Anne Holmes']\n",
      "- date_of_birth: ['February 3, 1984']\n",
      "- nationalities: ['American']\n",
      "- general_location: ['California, United States']\n",
      "- associated_orgs: ['Theranos']\n",
      "-----\n",
      "TOPIC: professional_timeline\n",
      "status: complete\n",
      "- roles: ['2003–2018: Theranos — Founder and CEO']\n",
      "- employers: ['Theranos']\n",
      "- board_positions: ['Harvard Medical School’s Board of Fellows']\n",
      "- education: ['Stanford University (2002-2004)']\n",
      "- role_dates: ['2003–2018: Theranos — Founder and CEO']\n",
      "-----\n",
      "TOPIC: legal_regulatory\n",
      "status: complete\n",
      "- criminal_records: ['Guilty of criminal fraud on four counts']\n",
      "- civil_cases: ['Theranos ABC lawsuit for unpaid promissory notes']\n",
      "- regulatory_actions: ['SEC charges for fraud']\n",
      "- sanctions_list_mentions: ['Elizabeth Holmes was banned from running a publicly traded company for ten years as part of a settlement with the SEC in 2018.']\n",
      "- court_involvement: ['United States v. Elizabeth Holmes']\n",
      "-----\n",
      "TOPIC: risk_inconsistencies\n",
      "status: unstarted\n",
      "- identity_conflicts: []\n",
      "- employment_conflicts: []\n",
      "- ownership_conflicts: []\n",
      "- timeline_gaps: []\n",
      "- misrepresentation_indicators: []\n"
     ]
    }
   ],
   "source": [
    "for o in out_data['results'][0]['report_text'].split('\\n\\n'):\n",
    "    print('-----')\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9378fbb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
